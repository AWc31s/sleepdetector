{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b4b50db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3808a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from facenet_models import FacenetModel\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.pyplot import text\n",
    "import skimage.io as io\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a310244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if (torch.cuda.is_available()):\n",
    "    print(\"GPU available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "903bd458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eyemodel import EyeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37edb0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.device'>\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.device('cuda')\n",
    "print(type(cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cd6ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, numpydata, numpylabels, transform=None, target_transform=None):\n",
    "        self.imgs = numpydata\n",
    "        self.img_labels = numpylabels\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.img_labels[idx]\n",
    "        image = self.imgs[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d5c9795",
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_x = np.empty((1,24,24))\n",
    "open_x = np.empty((1,24,24))\n",
    "\n",
    "for filename in glob.glob('train_dataset/closed*/*.*'):\n",
    "    img = np.array([cv.imread(filename, 0)])/255 + 1\n",
    "\n",
    "    closed_x = np.concatenate((closed_x, img))\n",
    "\n",
    "for filename in glob.glob('train_dataset/open*/*.*'):\n",
    "    img = np.array([cv.imread(filename, 0)])/255 + 1\n",
    "\n",
    "    open_x = np.concatenate((open_x, img))\n",
    "\n",
    "closed_x = closed_x[1:]\n",
    "open_x = open_x[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71ca35d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.vstack((closed_x[:int(len(closed_x)*0.8)], open_x[:int(len(open_x)*0.8)]))\n",
    "valid_x = np.vstack((closed_x[int(len(closed_x)*0.8):], open_x[int(len(open_x)*0.8):]))\n",
    "\n",
    "train_y = [0 for i in range(int(len(closed_x)*0.8))] + [1 for i in range(int(len(open_x)*0.8))]\n",
    "valid_y = [0 for i in range(len(closed_x) - int(len(closed_x)*0.8))] + [1 for i in range(len(open_x) - int(len(open_x)*0.8))]\n",
    "# print(train_y[-10])\n",
    "# print(train_y)\n",
    "train_x = torch.tensor(train_x, dtype=torch.float32, device=cuda)\n",
    "valid_x = torch.tensor(valid_x, dtype=torch.float32, device=cuda)\n",
    "\n",
    "train_y = torch.tensor(train_y, dtype=torch.float32, device=cuda)\n",
    "valid_y = torch.tensor(valid_y, dtype=torch.float32, device=cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c683ab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    o = torch.argmax(outputs, dim=1)\n",
    "#     print(o.shape)\n",
    "#     print(labels.shape)\n",
    "    return (sum(o == labels) / len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6997434b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    70] loss: 0.682\n",
      "[1,    70] accuracy: 0.5\n",
      "[2,    70] loss: 0.559\n",
      "[2,    70] accuracy: 0.71875\n",
      "[3,    70] loss: 0.437\n",
      "[3,    70] accuracy: 0.78125\n",
      "[4,    70] loss: 0.384\n",
      "[4,    70] accuracy: 0.78125\n",
      "[5,    70] loss: 0.327\n",
      "[5,    70] accuracy: 0.90625\n",
      "[6,    70] loss: 0.312\n",
      "[6,    70] accuracy: 1.0\n",
      "[7,    70] loss: 0.259\n",
      "[7,    70] accuracy: 0.9375\n",
      "[8,    70] loss: 0.245\n",
      "[8,    70] accuracy: 0.84375\n",
      "[9,    70] loss: 0.225\n",
      "[9,    70] accuracy: 0.90625\n",
      "[10,    70] loss: 0.219\n",
      "[10,    70] accuracy: 0.84375\n",
      "[11,    70] loss: 0.205\n",
      "[11,    70] accuracy: 0.96875\n",
      "[12,    70] loss: 0.186\n",
      "[12,    70] accuracy: 0.875\n",
      "[13,    70] loss: 0.178\n",
      "[13,    70] accuracy: 0.9375\n",
      "[14,    70] loss: 0.180\n",
      "[14,    70] accuracy: 0.96875\n",
      "[15,    70] loss: 0.171\n",
      "[15,    70] accuracy: 0.875\n",
      "[16,    70] loss: 0.178\n",
      "[16,    70] accuracy: 0.90625\n",
      "[17,    70] loss: 0.152\n",
      "[17,    70] accuracy: 0.96875\n",
      "[18,    70] loss: 0.148\n",
      "[18,    70] accuracy: 0.9375\n",
      "[19,    70] loss: 0.144\n",
      "[19,    70] accuracy: 0.875\n",
      "[20,    70] loss: 0.147\n",
      "[20,    70] accuracy: 0.96875\n",
      "[21,    70] loss: 0.151\n",
      "[21,    70] accuracy: 0.875\n",
      "[22,    70] loss: 0.138\n",
      "[22,    70] accuracy: 0.9375\n",
      "[23,    70] loss: 0.132\n",
      "[23,    70] accuracy: 0.96875\n",
      "[24,    70] loss: 0.132\n",
      "[24,    70] accuracy: 1.0\n",
      "[25,    70] loss: 0.131\n",
      "[25,    70] accuracy: 0.96875\n",
      "[26,    70] loss: 0.129\n",
      "[26,    70] accuracy: 1.0\n",
      "[27,    70] loss: 0.132\n",
      "[27,    70] accuracy: 1.0\n",
      "[28,    70] loss: 0.118\n",
      "[28,    70] accuracy: 0.96875\n",
      "[29,    70] loss: 0.125\n",
      "[29,    70] accuracy: 0.9375\n",
      "[30,    70] loss: 0.127\n",
      "[30,    70] accuracy: 0.90625\n",
      "[31,    70] loss: 0.110\n",
      "[31,    70] accuracy: 0.96875\n",
      "[32,    70] loss: 0.113\n",
      "[32,    70] accuracy: 0.90625\n",
      "[33,    70] loss: 0.106\n",
      "[33,    70] accuracy: 1.0\n",
      "[34,    70] loss: 0.117\n",
      "[34,    70] accuracy: 0.9375\n",
      "[35,    70] loss: 0.112\n",
      "[35,    70] accuracy: 1.0\n",
      "[36,    70] loss: 0.109\n",
      "[36,    70] accuracy: 0.96875\n",
      "[37,    70] loss: 0.103\n",
      "[37,    70] accuracy: 1.0\n",
      "[38,    70] loss: 0.113\n",
      "[38,    70] accuracy: 1.0\n",
      "[39,    70] loss: 0.112\n",
      "[39,    70] accuracy: 0.9375\n",
      "[40,    70] loss: 0.104\n",
      "[40,    70] accuracy: 0.96875\n",
      "[41,    70] loss: 0.099\n",
      "[41,    70] accuracy: 0.96875\n",
      "[42,    70] loss: 0.105\n",
      "[42,    70] accuracy: 0.875\n",
      "[43,    70] loss: 0.097\n",
      "[43,    70] accuracy: 0.96875\n",
      "[44,    70] loss: 0.095\n",
      "[44,    70] accuracy: 1.0\n",
      "[45,    70] loss: 0.103\n",
      "[45,    70] accuracy: 1.0\n",
      "[46,    70] loss: 0.102\n",
      "[46,    70] accuracy: 1.0\n",
      "[47,    70] loss: 0.102\n",
      "[47,    70] accuracy: 0.96875\n",
      "[48,    70] loss: 0.106\n",
      "[48,    70] accuracy: 0.9375\n",
      "[49,    70] loss: 0.097\n",
      "[49,    70] accuracy: 0.96875\n",
      "[50,    70] loss: 0.093\n",
      "[50,    70] accuracy: 0.9375\n",
      "[51,    70] loss: 0.106\n",
      "[51,    70] accuracy: 0.96875\n",
      "[52,    70] loss: 0.095\n",
      "[52,    70] accuracy: 0.96875\n",
      "[53,    70] loss: 0.095\n",
      "[53,    70] accuracy: 0.96875\n",
      "[54,    70] loss: 0.095\n",
      "[54,    70] accuracy: 1.0\n",
      "[55,    70] loss: 0.088\n",
      "[55,    70] accuracy: 0.9375\n",
      "[56,    70] loss: 0.087\n",
      "[56,    70] accuracy: 1.0\n",
      "[57,    70] loss: 0.108\n",
      "[57,    70] accuracy: 0.96875\n",
      "[58,    70] loss: 0.090\n",
      "[58,    70] accuracy: 1.0\n",
      "[59,    70] loss: 0.084\n",
      "[59,    70] accuracy: 0.9375\n",
      "[60,    70] loss: 0.093\n",
      "[60,    70] accuracy: 1.0\n",
      "[61,    70] loss: 0.088\n",
      "[61,    70] accuracy: 0.96875\n",
      "[62,    70] loss: 0.093\n",
      "[62,    70] accuracy: 0.96875\n",
      "[63,    70] loss: 0.084\n",
      "[63,    70] accuracy: 1.0\n",
      "[64,    70] loss: 0.088\n",
      "[64,    70] accuracy: 1.0\n",
      "[65,    70] loss: 0.083\n",
      "[65,    70] accuracy: 1.0\n",
      "[66,    70] loss: 0.083\n",
      "[66,    70] accuracy: 1.0\n",
      "[67,    70] loss: 0.084\n",
      "[67,    70] accuracy: 0.96875\n",
      "[68,    70] loss: 0.076\n",
      "[68,    70] accuracy: 0.96875\n",
      "[69,    70] loss: 0.084\n",
      "[69,    70] accuracy: 1.0\n",
      "[70,    70] loss: 0.082\n",
      "[70,    70] accuracy: 0.96875\n",
      "[71,    70] loss: 0.078\n",
      "[71,    70] accuracy: 1.0\n",
      "[72,    70] loss: 0.080\n",
      "[72,    70] accuracy: 0.9375\n",
      "[73,    70] loss: 0.083\n",
      "[73,    70] accuracy: 0.9375\n",
      "[74,    70] loss: 0.080\n",
      "[74,    70] accuracy: 1.0\n",
      "[75,    70] loss: 0.080\n",
      "[75,    70] accuracy: 0.96875\n",
      "[76,    70] loss: 0.100\n",
      "[76,    70] accuracy: 1.0\n",
      "[77,    70] loss: 0.077\n",
      "[77,    70] accuracy: 0.9375\n",
      "[78,    70] loss: 0.067\n",
      "[78,    70] accuracy: 0.9375\n",
      "[79,    70] loss: 0.098\n",
      "[79,    70] accuracy: 0.96875\n",
      "[80,    70] loss: 0.068\n",
      "[80,    70] accuracy: 1.0\n",
      "[81,    70] loss: 0.075\n",
      "[81,    70] accuracy: 1.0\n",
      "[82,    70] loss: 0.072\n",
      "[82,    70] accuracy: 0.96875\n",
      "[83,    70] loss: 0.069\n",
      "[83,    70] accuracy: 1.0\n",
      "[84,    70] loss: 0.077\n",
      "[84,    70] accuracy: 0.9375\n",
      "[85,    70] loss: 0.075\n",
      "[85,    70] accuracy: 1.0\n",
      "[86,    70] loss: 0.077\n",
      "[86,    70] accuracy: 1.0\n",
      "[87,    70] loss: 0.078\n",
      "[87,    70] accuracy: 0.9375\n",
      "[88,    70] loss: 0.080\n",
      "[88,    70] accuracy: 0.90625\n",
      "[89,    70] loss: 0.070\n",
      "[89,    70] accuracy: 1.0\n",
      "[90,    70] loss: 0.074\n",
      "[90,    70] accuracy: 0.96875\n",
      "[91,    70] loss: 0.081\n",
      "[91,    70] accuracy: 0.9375\n",
      "[92,    70] loss: 0.071\n",
      "[92,    70] accuracy: 1.0\n",
      "[93,    70] loss: 0.075\n",
      "[93,    70] accuracy: 0.96875\n",
      "[94,    70] loss: 0.079\n",
      "[94,    70] accuracy: 1.0\n",
      "[95,    70] loss: 0.066\n",
      "[95,    70] accuracy: 0.96875\n",
      "[96,    70] loss: 0.070\n",
      "[96,    70] accuracy: 0.9375\n",
      "[97,    70] loss: 0.068\n",
      "[97,    70] accuracy: 1.0\n",
      "[98,    70] loss: 0.065\n",
      "[98,    70] accuracy: 0.875\n",
      "[99,    70] loss: 0.075\n",
      "[99,    70] accuracy: 0.96875\n",
      "[100,    70] loss: 0.066\n",
      "[100,    70] accuracy: 0.96875\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model = EyeModel().to(cuda)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "data = CustomImageDataset(train_x, train_y)\n",
    "trainloader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.reshape(len(inputs),1,24,24)#.float()\n",
    "        labels = labels.long()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 70 == 69:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 70:.3f}')\n",
    "            running_loss = 0.0\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] accuracy: {accuracy(outputs, labels)}')\n",
    "    \n",
    "    \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb5bb4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a337b959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.14131179451942444\n",
      "accuracy: 0.9536082744598389\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"model.pb\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "batch_size = len(valid_x)\n",
    "\n",
    "valid_data = CustomImageDataset(valid_x, valid_y)\n",
    "valid_trainloader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    running_loss = 0.0\n",
    "    for i, v_data in enumerate(valid_trainloader, 0):\n",
    "        v_inputs, v_labels = v_data\n",
    "        v_inputs = v_inputs.reshape(len(v_inputs),1,24,24)#.float()\n",
    "        v_labels = v_labels.long()\n",
    "        \n",
    "        # forward\n",
    "        v_outputs = model(v_inputs)\n",
    "        loss = criterion(v_outputs, v_labels)\n",
    "\n",
    "        # print statistics\n",
    "#         running_loss += loss.item()\n",
    "#         print(f'loss: {running_loss / 2000:.3f}')\n",
    "        print(f'loss: {loss}')\n",
    "        print(f'accuracy: {accuracy(v_outputs, v_labels)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
